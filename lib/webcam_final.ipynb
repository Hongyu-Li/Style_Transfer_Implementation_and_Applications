{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Webcam_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "UiJsDNDRMBbS",
        "colab_type": "code",
        "outputId": "680d5960-aba6-40e4-eec0-f6d2dde06407",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Eager Mode\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()    \n",
        "import tensorflow.contrib.eager as tfe\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly())) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager execution: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1GlRLH0MBba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "from os import listdir\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "from tensorflow.python.keras import models\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import urllib\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "\n",
        "from IPython import display\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Flatten, Reshape, BatchNormalization, Dropout,Add"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wz8XkSvbYPcW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Webcam Application"
      ]
    },
    {
      "metadata": {
        "id": "1JDyFiFKYUO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is used to implement webcam based on fast neural style transfer algorithm. This could be run end-to-end but this should be run locally rather than colab! "
      ]
    },
    {
      "metadata": {
        "id": "oYrErwJ8YsEn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load Model"
      ]
    },
    {
      "metadata": {
        "id": "tWQyV_UVMBbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TransformNet(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(TransformNet, self).__init__()\n",
        "    # encode block\n",
        "    self.block1_conv1 = Conv2D(filters=32, kernel_size=(9,9), strides=1, padding=\"same\")\n",
        "    self.block1_batchnorm1 = BatchNormalization(axis=3)\n",
        "    self.block1_conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=2, padding=\"same\")\n",
        "    self.block1_batchnorm2 = BatchNormalization(axis=3)\n",
        "    self.block1_conv3 = Conv2D(filters=128, kernel_size=(3,3), strides=2, padding=\"same\")\n",
        "    self.block1_batchnorm3 = BatchNormalization(axis=3)\n",
        "    # residual net block\n",
        "    self.block2_conv1 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm1 = BatchNormalization(axis=3)\n",
        "    self.block2_conv2 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm2 = BatchNormalization(axis=3)\n",
        "    self.block2_add1 = Add()\n",
        "    self.block2_conv3 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm3 = BatchNormalization(axis=3)\n",
        "    self.block2_conv4 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm4 = BatchNormalization(axis=3)\n",
        "    self.block2_add2 = Add()\n",
        "    self.block2_conv5 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm5 = BatchNormalization(axis=3)\n",
        "    self.block2_conv6 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm6 = BatchNormalization(axis=3)\n",
        "    self.block2_add3 = Add()\n",
        "    self.block2_conv7 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm7 = BatchNormalization(axis=3)\n",
        "    self.block2_conv8 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm8 = BatchNormalization(axis=3)\n",
        "    self.block2_add4 = Add()\n",
        "    self.block2_conv9 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm9 = BatchNormalization(axis=3)\n",
        "    self.block2_conv10 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
        "    self.block2_batchnorm10 = BatchNormalization(axis=3)\n",
        "    self.block2_add5 = Add()\n",
        "    # decode block\n",
        "    self.block3_conv1transpose = Conv2DTranspose(filters=64, kernel_size=(3,3), strides=2, padding=\"same\")\n",
        "    self.block3_batchnorm1 = BatchNormalization(axis=3)\n",
        "    self.block3_conv2transpose = Conv2DTranspose(filters=32, kernel_size=(3,3), strides=2, padding=\"same\")\n",
        "    self.block3_batchnorm2 = BatchNormalization(axis=3)\n",
        "    self.block3_conv3transpose = Conv2D(filters=3, kernel_size=(9,9), strides=1, padding=\"same\")\n",
        "    self.block3_batchnorm3 = BatchNormalization(axis=3)\n",
        "    \n",
        "  def call(self, x, training=True):\n",
        "    # encode block\n",
        "    x = tf.reshape(x,(-1,512,512,3))\n",
        "    x = self.block1_conv1(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block1_batchnorm1(x, training=training)\n",
        "    x = self.block1_conv2(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block1_batchnorm2(x, training=training)\n",
        "    x = self.block1_conv3(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block1_batchnorm3(x, training=training)\n",
        "    \n",
        "    # residual block\n",
        "    x1 = x\n",
        "    x = self.block2_conv1(x)\n",
        "    x = self.block2_batchnorm1(x,training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block2_conv2(x)\n",
        "    x = self.block2_batchnorm2(x,training=training)\n",
        "    x = self.block2_add1([x, x1])\n",
        "    x1 = x\n",
        "    x = self.block2_conv3(x)\n",
        "    x = self.block2_batchnorm3(x,training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block2_conv4(x)\n",
        "    x = self.block2_batchnorm4(x,training=training)\n",
        "    x = self.block2_add2([x, x1])\n",
        "    x1 = x\n",
        "    x = self.block2_conv5(x)\n",
        "    x = self.block2_batchnorm5(x,training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block2_conv6(x)\n",
        "    x = self.block2_batchnorm6(x,training=training)\n",
        "    x = self.block2_add3([x, x1])\n",
        "    x1 = x\n",
        "    x = self.block2_conv7(x)\n",
        "    x = self.block2_batchnorm7(x,training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block2_conv8(x)\n",
        "    x = self.block2_batchnorm8(x,training=training)\n",
        "    x = self.block2_add4([x, x1])\n",
        "    x1 = x\n",
        "    x = self.block2_conv9(x)\n",
        "    x = self.block2_batchnorm9(x,training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block2_conv10(x)\n",
        "    x = self.block2_batchnorm10(x,training=training)\n",
        "    x = self.block2_add5([x, x1])\n",
        "    \n",
        "    # decode block\n",
        "    x = self.block3_conv1transpose(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block3_batchnorm1(x,training=training)\n",
        "    x = self.block3_conv2transpose(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.block3_batchnorm2(x,training=training)\n",
        "    x = self.block3_conv3transpose(x)\n",
        "    x = (tf.nn.tanh(x)+1)*127.5  \n",
        "    #so as to input vgg16, this idea comes from \n",
        "    # https://github.com/malhagi/tensorflow-fast-neuralstyle\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNRm02LTY7Wg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load weights for Starry Night"
      ]
    },
    {
      "metadata": {
        "id": "UreXVUtqMBbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    transform_net=TransformNet()\n",
        "    # Initialize somehow!\n",
        "    _=transform_net(tfe.Variable(np.zeros((1,512,512,3),dtype=np.float32)), training=True)\n",
        "    web='http://www.columbia.edu/~hl3099/aml/beta_model_style_1.h5' \n",
        "    urllib.request.urlretrieve(web,'beta_model_style_1.h5')\n",
        "    transform_net.load_weights('beta_model_style_1.h5',by_name=False)\n",
        "    return transform_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PB-03pNUMBbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_net=load_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Vtzgdq6ZjCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: `beta_model_style_1.h5` is the weights for starry night,  `beta_model_style_2.h5` is the weights for Victoire,  `beta_model_style_3.h5` is the weights for Women at Their Toilette and `beta_model_style_4.h5` is the weights for google map. "
      ]
    },
    {
      "metadata": {
        "id": "NdDcWOxTZHV-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Style Transfer on Webcam"
      ]
    },
    {
      "metadata": {
        "id": "MtlvwoBdMBbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def style_transfer_test_data(img,width,height):\n",
        "  \n",
        "    # read data\n",
        "    #test_image = Image.open(i)\n",
        "    img=cv2.resize(img, (width, height)) \n",
        "    test_image = np.array(img,dtype='float32')\n",
        "    test_image = kp_image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image,axis=0)\n",
        "    test_image /= 255\n",
        "    #test_images[0,:,:,:]=np.asarray(test_image, dtype='float32')\n",
        "  \n",
        "    # predictions\n",
        "    test_img=transform_net(test_image,training=False)\n",
        "    test_img=test_img.numpy()\n",
        "    test_img=test_img[0,:,:,:]\n",
        "    return np.clip(test_img,0,255).astype('uint8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUkcilrjMBbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "count = 0\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Draw a rectangle around the faces\n",
        "    #for (x, y, w, h) in faces:\n",
        "    #    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    with tf.device('/gpu:0'):\n",
        "        frame=style_transfer_test_data(frame,512,512)\n",
        "    \n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Video', frame[:,:,::-1])\n",
        "    #cv2.imwrite(\"frame%d.jpg\" % count, frame)\n",
        "    \n",
        "    #content_image_path = \"frame%d.jpg\" % count\n",
        "    #create white noise image and load target images\n",
        "    #content_image,_= load_and_preprocess_img(content_image_path,height,width,means)\n",
        "    #style_image,_= load_and_preprocess_img(style_image_path,height,width,means)\n",
        "    #best_loss,best_img=transfer_style(height,width,init_way,means,layers_content,layers_style,\n",
        "    #                                  content_weight,style_weight,variation_weight,beta,iterations)    \n",
        "    count += 1\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything is done, release the capture\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0CGJ9-JRZObu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: If camera does not pop out, just re-run the whole notebook. "
      ]
    }
  ]
}