{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "#Eager Mode\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()    \n",
    "import tensorflow.contrib.eager as tfe\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from tensorflow.python.keras import models\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import urllib\n",
    "from tensorflow.python.keras.preprocessing import image as kp_image\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Flatten, Reshape, BatchNormalization, Dropout,Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformNet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(TransformNet, self).__init__()\n",
    "    # encode block\n",
    "    self.block1_conv1 = Conv2D(filters=32, kernel_size=(9,9), strides=1, padding=\"same\")\n",
    "    self.block1_batchnorm1 = BatchNormalization(axis=3)\n",
    "    self.block1_conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=2, padding=\"same\")\n",
    "    self.block1_batchnorm2 = BatchNormalization(axis=3)\n",
    "    self.block1_conv3 = Conv2D(filters=128, kernel_size=(3,3), strides=2, padding=\"same\")\n",
    "    self.block1_batchnorm3 = BatchNormalization(axis=3)\n",
    "    # residual net block\n",
    "    self.block2_conv1 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm1 = BatchNormalization(axis=3)\n",
    "    self.block2_conv2 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm2 = BatchNormalization(axis=3)\n",
    "    self.block2_add1 = Add()\n",
    "    self.block2_conv3 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm3 = BatchNormalization(axis=3)\n",
    "    self.block2_conv4 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm4 = BatchNormalization(axis=3)\n",
    "    self.block2_add2 = Add()\n",
    "    self.block2_conv5 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm5 = BatchNormalization(axis=3)\n",
    "    self.block2_conv6 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm6 = BatchNormalization(axis=3)\n",
    "    self.block2_add3 = Add()\n",
    "    self.block2_conv7 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm7 = BatchNormalization(axis=3)\n",
    "    self.block2_conv8 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm8 = BatchNormalization(axis=3)\n",
    "    self.block2_add4 = Add()\n",
    "    self.block2_conv9 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm9 = BatchNormalization(axis=3)\n",
    "    self.block2_conv10 = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\")\n",
    "    self.block2_batchnorm10 = BatchNormalization(axis=3)\n",
    "    self.block2_add5 = Add()\n",
    "    # decode block\n",
    "    self.block3_conv1transpose = Conv2DTranspose(filters=64, kernel_size=(3,3), strides=2, padding=\"same\")\n",
    "    self.block3_batchnorm1 = BatchNormalization(axis=3)\n",
    "    self.block3_conv2transpose = Conv2DTranspose(filters=32, kernel_size=(3,3), strides=2, padding=\"same\")\n",
    "    self.block3_batchnorm2 = BatchNormalization(axis=3)\n",
    "    self.block3_conv3transpose = Conv2D(filters=3, kernel_size=(9,9), strides=1, padding=\"same\")\n",
    "    self.block3_batchnorm3 = BatchNormalization(axis=3)\n",
    "    \n",
    "  def call(self, x, training=True):\n",
    "    # encode block\n",
    "    x = tf.reshape(x,(-1,512,512,3))\n",
    "    x = self.block1_conv1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block1_batchnorm1(x, training=training)\n",
    "    x = self.block1_conv2(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block1_batchnorm2(x, training=training)\n",
    "    x = self.block1_conv3(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block1_batchnorm3(x, training=training)\n",
    "    \n",
    "    # residual block\n",
    "    x1 = x\n",
    "    x = self.block2_conv1(x)\n",
    "    x = self.block2_batchnorm1(x,training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block2_conv2(x)\n",
    "    x = self.block2_batchnorm2(x,training=training)\n",
    "    x = self.block2_add1([x, x1])\n",
    "    x1 = x\n",
    "    x = self.block2_conv3(x)\n",
    "    x = self.block2_batchnorm3(x,training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block2_conv4(x)\n",
    "    x = self.block2_batchnorm4(x,training=training)\n",
    "    x = self.block2_add2([x, x1])\n",
    "    x1 = x\n",
    "    x = self.block2_conv5(x)\n",
    "    x = self.block2_batchnorm5(x,training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block2_conv6(x)\n",
    "    x = self.block2_batchnorm6(x,training=training)\n",
    "    x = self.block2_add3([x, x1])\n",
    "    x1 = x\n",
    "    x = self.block2_conv7(x)\n",
    "    x = self.block2_batchnorm7(x,training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block2_conv8(x)\n",
    "    x = self.block2_batchnorm8(x,training=training)\n",
    "    x = self.block2_add4([x, x1])\n",
    "    x1 = x\n",
    "    x = self.block2_conv9(x)\n",
    "    x = self.block2_batchnorm9(x,training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block2_conv10(x)\n",
    "    x = self.block2_batchnorm10(x,training=training)\n",
    "    x = self.block2_add5([x, x1])\n",
    "    \n",
    "    # decode block\n",
    "    x = self.block3_conv1transpose(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block3_batchnorm1(x,training=training)\n",
    "    x = self.block3_conv2transpose(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.block3_batchnorm2(x,training=training)\n",
    "    x = self.block3_conv3transpose(x)\n",
    "    x = (tf.nn.tanh(x)+1)*127.5  \n",
    "    #so as to input vgg16, this idea comes from \n",
    "    # https://github.com/malhagi/tensorflow-fast-neuralstyle\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    transform_net=TransformNet()\n",
    "    # Initialize somehow!\n",
    "    _=transform_net(tfe.Variable(np.zeros((1,512,512,3),dtype=np.float32)), training=True)\n",
    "    web='http://www.columbia.edu/~hl3099/aml/beta_model.h5' \n",
    "    urllib.request.urlretrieve(web,'beta_model.h5')\n",
    "    transform_net.load_weights('beta_model.h5',by_name=False)\n",
    "    return transform_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_net=load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer_test_data(img,width,height):\n",
    "  \n",
    "    # read data\n",
    "    #test_image = Image.open(i)\n",
    "    img=cv2.resize(img, (width, height)) \n",
    "    test_image = np.array(img,dtype='float32')\n",
    "    test_image = kp_image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "    test_image /= 255\n",
    "    #test_images[0,:,:,:]=np.asarray(test_image, dtype='float32')\n",
    "  \n",
    "    # predictions\n",
    "    test_img=transform_net(test_image,training=False)\n",
    "    test_img=test_img.numpy()\n",
    "    test_img=test_img[0,:,:,:]\n",
    "    return np.clip(test_img,0,255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    #for (x, y, w, h) in faces:\n",
    "    #    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    with tf.device('/gpu:0'):\n",
    "        frame=style_transfer_test_data(frame,512,512)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame[:,:,::-1])\n",
    "    #cv2.imwrite(\"frame%d.jpg\" % count, frame)\n",
    "    \n",
    "    #content_image_path = \"frame%d.jpg\" % count\n",
    "    #create white noise image and load target images\n",
    "    #content_image,_= load_and_preprocess_img(content_image_path,height,width,means)\n",
    "    #style_image,_= load_and_preprocess_img(style_image_path,height,width,means)\n",
    "    #best_loss,best_img=transfer_style(height,width,init_way,means,layers_content,layers_style,\n",
    "    #                                  content_weight,style_weight,variation_weight,beta,iterations)    \n",
    "    count += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
